<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Adaptive Diffusion Policy Project</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #f4f4f4;
            color: #333;
            line-height: 1.6;
            margin: 0;
            padding: 0;
        }
        header {
            background-color: #0056b3;
            color: #fff;
            padding: 20px 0;
            text-align: center;
        }
        header h1 {
            margin: 0;
            font-size: 2.5em;
        }
        section {
            max-width: 900px;
            margin: 20px auto;
            padding: 20px;
            background-color: #fff;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }
        section h2 {
            color: #0056b3;
            margin-bottom: 15px;
        }
        section p {
            margin-bottom: 20px;
        }
        section ul {
            margin-bottom: 20px;
        }
        footer {
            text-align: center;
            background-color: #0056b3;
            color: white;
            padding: 10px 0;
            margin-top: 20px;
        }
        footer a {
            color: #fff;
            text-decoration: underline;
        }
    </style>
</head>
<body>

<header>
    <h1>Adaptive Diffusion Policy (ADP) for Legged Locomotion</h1>
</header>

<section>
    <h2>Overview</h2>
    <p>ADP is a groundbreaking approach for improving legged robot locomotion across diverse terrains. By combining advanced diffusion models with visual perception and reinforcement learning techniques, ADP enables quadrupedal robots to adapt and perform reliably in complex, dynamic environments.</p>
</section>

<section>
    <h2>Key Features</h2>
    <ul>
        <li><strong>Innovative Diffusion Policy for Locomotion:</strong> Our method employs a diffusion policy that generates action sequences from robot observations. Using a Transformer backbone, ADP captures complex temporal dependencies for precise, robust movement control.</li>
        <li><strong>Vision-Guided Locomotion:</strong> ADP integrates visual input from a depth camera, enabling the robot to perceive its environment and navigate obstacles with real-time adaptability.</li>
        <li><strong>Dual-Stage Training Approach:</strong> The policy is first pretrained offline using an extensive dataset of diverse terrains, followed by online fine-tuning using reinforcement learning to optimize robot performance across different real-world environments.</li>
    </ul>
</section>

<section>
    <h2>Experimental Results</h2>
    <p>ADP has been tested on four terrain types—flat, gap, slope, and step—using the Unitree A1 quadrupedal robot. The fine-tuning phase significantly improves performance on complex terrains compared to traditional reinforcement learning methods.</p>
    <ul>
        <li>Superior generalization and adaptability.</li>
        <li>Efficient locomotion with minimal training data (only 1% of what traditional RL requires).</li>
        <li>Enhanced robustness and stability on challenging terrains.</li>
    </ul>
</section>

<section>
    <h2>Potential Applications</h2>
    <ul>
        <li><strong>Search and Rescue Missions:</strong> Navigating rough and unpredictable terrains.</li>
        <li><strong>Agriculture Robotics:</strong> Efficient movement across varied ground conditions.</li>
        <li><strong>Exploration Robotics:</strong> Autonomous traversal of unexplored or dangerous environments.</li>
    </ul>
</section>

<section>
    <h2>Join Us</h2>
    <p>For more information or collaboration opportunities, contact our team or explore our <a href="#">GitHub repository (coming soon)</a> to access our code and contribute to further developments in robotic locomotion.</p>
</section>

<footer>
    <p>&copy; 2024 ADP Project. All Rights Reserved.</p>
</footer>

</body>
</html>
